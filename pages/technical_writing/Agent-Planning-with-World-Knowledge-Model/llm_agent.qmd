---
title: "Agent Planning with World Knowledge Model"
description: |
    Agent Planning 단계에서 real-world 지식을 도입하는 방법
date: "2024-05-10"
author: "Junwoo Kim"
image: "./noah.jpeg"
draft: False
---


## Research Topic & Purpose

Recent endeavors towards directly using large language models (LLMs) as agent models to execute interactive planning tasks have shown commendable results. Despite their achievements, however, they still struggle with brainless trial-and-error in global planning and generating hallucinatory actions in local planning due to their poor understanding of the "real" physical world.

- 최근 대형 언어 모델(LLMs)을 에이전트 모델로 직접 사용하여 대화형 계획 작업을 수행하려는 시도는 높이 평가할 만한 결과를 보여주었지만, "실제" 물리 세계에 대한 이해 부족으로 전역 계획에서의 무분별한 시행착오와 지역 계획에서의 환각 동작 생성 문제가 여전히 남아 있음.


Imitating humans' mental world knowledge model which provides global prior knowledge before the task and maintains local dynamic knowledge during the task, in this paper, we introduce parametric World Knowledge Model (WKM) to facilitate agent planning.

- 이 논문에서는 작업 전 전역 사전 지식을 제공하고 작업 중 지역 동적 지식을 유지하는 인간의 정신 세계 지식 모델을 모방하여, 에이전트 계획을 돕기 위해 매개변수 World Knowledge Model(WKM)을 도입함.

## Methodology

Specifically, we first steer the agent model to synthesize task knowledge from the comparison between expert and sampled trajectories. 

- 구체적으로, 먼저 전문가 궤적과 샘플링된 궤적 간 비교를 통해 작업 지식을 합성하도록 에이전트 모델을 유도함

Then we prompt it to summarize state knowledge for each planning step from expert trajectories and combine the previous and next actions to build a state knowledge base.

- 그 다음 전문가 궤적에서 각 계획 단계별 상태 지식을 요약하고 이전/다음 행동을 결합하여 상태 지식 베이스를 구축하도록 프롬프트를 제공함. 

Lastly, we integrate the generated knowledge into expert trajectories and train a WKM

- 마지막으로 생성된 지식을 전문가 궤적에 통합하고 WKM을 훈련시킴

The agent model needs to be retrained to adapt to the task knowledge. Note our agent and knowledge model are both trained with LoRA sharing the same backbone.

- 에이전트 모델은 작업 지식에 적응하기 위해 재훈련되어야 함. 에이전트와 지식 모델은 동일한 backbone을 공유하는 LoRA로 훈련됨.


## Experiment Analysis
We evaluate our method on three real-world simulated planning tasks: ALFWorld, WebShop, and ScienceWorld with three state-of-the-art open-source LLMs, Mistral-7B, Gemma-7B, and Llama-3-8B.

- ALFWorld, WebShop, ScienceWorld의 세 가지 실제 시뮬레이션 계획 작업에 대해 Mistral-7B, Gemma-7B, Llama-3-8B의 세 가지 최신 오픈소스 LLM으로 제안 방법을 평가함.


Experimental results on three complex real-world simulated datasets with three state-of-the-art open-source LLMs, Mistral-7B, Gemma-7B, and Llama-3-8B, demonstrate that our method can achieve superior performance compared to various strong baselines.

- 세 가지 최신 오픈소스 LLM을 사용한 세 개의 복잡한 실제 시뮬레이션 데이터셋에 대한 실험 결과, 제안 방법이 다양한 강력한 기준선에 비해 우수한 성능을 달성할 수 있음을 입증함.

Besides, we analyze to illustrate that our WKM can effectively alleviate the blind trial-and-error and hallucinatory action issues, providing strong support for the agent's understanding of the world.

- 또한 WKM이 맹목적 시행착오와 환각 동작 문제를 효과적으로 완화하여 에이전트의 세계 이해를 강력히 뒷받침할 수 있음을 보여줌.


Other interesting findings include: 1) our instance-level task knowledge can generalize better to unseen tasks, 2) weak WKM can guide strong agent model planning, and 3) unified WKM training has promising potential for further development.

- 다른 흥미로운 발견으로는 1) 인스턴스 수준 작업 지식이 보이지 않는 작업에 더 잘 일반화될 수 있고, 2) 약한 WKM이 강한 에이전트 모델 계획을 안내할 수 있으며, 3) 통합 WKM 훈련이 추가 개발을 위해 유망한 잠재력을 가짐.




