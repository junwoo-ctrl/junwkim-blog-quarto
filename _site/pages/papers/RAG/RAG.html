<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Junwoo Kim">
<meta name="dcterms.date" content="2023-12-27">
<meta name="description" content="LLM이 가진 약점을 타파하려는 현시점 가장 유의미한 시도를 정리합니다.">

<title>junwkim’s blog - RAG: Retrieval Augmented Generation for Knowledge-Intensive NLP Task.</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="../../../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../../../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">junwkim’s blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../pages/technical_writing.html"> 
<span class="menu-text">technical writing</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../pages/posts.html"> 
<span class="menu-text">posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../pages/papers.html"> 
<span class="menu-text">papers</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../main.html"> 
<span class="menu-text">Back To Home</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">RAG: Retrieval Augmented Generation for Knowledge-Intensive NLP Task.</h1>
</div>

<div>
  <div class="description">
    <p>LLM이 가진 약점을 타파하려는 현시점 가장 유의미한 시도를 정리합니다.</p>
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Junwoo Kim </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 27, 2023</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="large-language-model-open-domain-question-answering" class="level2">
<h2 class="anchored" data-anchor-id="large-language-model-open-domain-question-answering">Large Language Model, Open-Domain Question Answering</h2>
<p>일반적으로 LLM은 방대한 양의 데이터를 기반으로 사전학습(Pre-Trained)된 GPT Based Model을 의미한다. GPT는 Next-Token-Prediction을 수행하는 Pretraining 과정을 거치며 자연어 테스크들에서 유의미한 성과들을 보여왔다.</p>
<p>LLM을 활용하려는 시도 중 하나는 LLM에 질문을 하고 올바른(품질이 좋은) 답변을 얻는 것이다. 이러한 분야를 Open-Domain Question Answering(ODQA)라고 정의한다. 따라서 ODQA에서는 input text를 question으로, output text를 answer로 하는 Framework로 정의한다.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
A[Who was Cleopatra?] --&gt; B[LLM]
B --&gt; C[Cleopatra was a famous Egyptian queen.]

style A fill:#fff,stroke:#000,color:#000
style B fill:#fff,stroke:#000,color:#000
style C fill:#fff,stroke:#000,color:#000
linkStyle 0 stroke:#000, stroke-width:1px, stroke-linecap:butt;
linkStyle 1 stroke:#000, stroke-width:1px, stroke-linecap:square;
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>질문을 입력하면 답변을 생성한다는 점에서 LLM을 QA Task에서 생성하는 것이 굉장히 주목을 받게 되었다. 그런데 답변을 생성해내는 것까지는 좋은 일인데, LLM에 아주 잘못된 입력을 해도 그럴듯하게 답변을 생성해내는 Hallucination 현상이 대두되었다.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
A[Who is the brave Korean Cleopatra?]
style A fill:#fff,stroke:#000,color:#000

B[LLM]
style B fill:#fff,stroke:#000,color:#000

C[She was a very brave and famous independence activist.]
style C fill:#fff,stroke:#000,color:#000

A --&gt; B
linkStyle 0 stroke:#000, stroke-width:1px, stroke-linecap:butt;

B --&gt; C
linkStyle 1 stroke:#000, stroke-width:1px, stroke-linecap:butt;
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>Example of Hallucination</p>
<p>또한, QA Task의 용도로 사용하기에는 단편적이고 간단한 답변을 내놓는 경향이 있다. 이러한 단점을 보강하기 위해 한동안은 Hallucination을 피하고 답변의 생성을 도와주기 위해 Context를 붙이는 방식이 선호되었다.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
A[Who is the brave Korean Cleopatra?]
style A fill:#fff,stroke:#000,color:#000

B[LLM]
style B fill:#fff,stroke:#000,color:#000

C[She was a very brave and famous independence activist.]
style C fill:#fff,stroke:#000,color:#000

subgraph Context
D[We are talking about ancient romain history.]
style D fill:#fff,stroke:#000,color:#000
end
style Context fill:#fff,stroke:#000,color:#000


A --&gt; B
linkStyle 0 stroke:#000, stroke-width:1px, stroke-linecap:butt;

B --&gt; C
linkStyle 1 stroke:#000, stroke-width:1px, stroke-linecap:butt;

D --&gt; B
linkStyle 2 stroke:#000, stroke-width:1px, stroke-linecap:butt;
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>Context를 입력 프롬프트에 추가하는 방식이 동작하는 이유는 근본적으로 GPT는 Next Token Prediction을 수행하는 모델이기 때문이다. 앞서 등장한 Token들과 연관이 큰 답변을 생성해야하니 Context를 잘 조절하면 Hallucination을 막는것은 물론 질 좋은 답변을 생성하는 데에도 도움이 된다.</p>
<p>그러나 세상에 존재하는 Question은 사실상 무한하고, Question마다 의미있는 Context를 생성하는 작업은 무척 비효율적이다. 또한, Knowledge Intensive한 경우 Context를 생성하는 비용 자체가 비싸다는 단점이 있다. RAG(Retrieval Augmented Generation)은 이러한 문제를 해결하기 위해 제시되었다.</p>
</section>
<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<p>Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures.</p>
<ul>
<li>대규모 사전훈련 모델은 사실적인 정보들을 파라미터에 저장하고, 이를 통해 downstream NLP task에서 state-of-the-art 결과를 보여왔다.</li>
<li>그런 연구들에서 지식을 정밀하게 조작하고 접근하는 능력은 한계가 있었고, 그러므로 이러한 구조는 knowledge-intensive한 task들에서는 성능저하가 발생했다.</li>
</ul>
<p>Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems.</p>
<ul>
<li>추가적으로, 모델의 decisions에 대한 근거를 제공하거나 새로운 knowledge를 업데이트 하는 것은 여전히 문제로 남아있다</li>
</ul>
<p>We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) — models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever.</p>
<ul>
<li>우리는 검색증강 생성(RAG)을 위한 fine-tunning recipe를 찾아보았고, 언어 생성을 위한 pretrained parametric 모델과 non-parametric memory로 구성된 모델구조를 제안한다.</li>
<li>RAG 모델은 사전훈련된 Seq2Seq 모델과 Dense Vector로 구성된 Knowledge Index, 그리고 Index에 접근하기 위한 pre-trained neural retriever로 구성되었다.</li>
</ul>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Pre-trained neural language models have been shown to learn a substantial amount of in-depth knowledge from data. They can do so without any access to an external memory, as a parameterized implicit knowledge base. While this development is exciting, such models do have downsides: They cannot easily expand or revise their memory, can’t straightforwardly provide insight into their predictions, and may produce “hallucinations”.</p>
<ul>
<li>pre-trained neural language models은 데이터로부터 상당한 양의 지식을 배우는 것으로 보여졌고, external memory나 knowledge base에 접근하지 않고서도 가능하다고 여겨졌다.</li>
<li>이런 발전은 흥미로웠지만, memory를 쉽게 확장하거나 수정하지 못했고 prediction에 대한 직접적인 근거를 제시하지 못했고, Hallucinations를 발생시켰다.</li>
</ul>
<p>Here, we bring hybrid parametric and non-parametric memory to the “workhorse of NLP,” i.e.&nbsp;sequence-to-sequence (seq2seq) models. We build RAG models where the parametric memory is a pre-trained seq2seq transformer, and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever.</p>
<ul>
<li>우리는 NLP Task에서는 정석이라고 할 수 있는 Seq2Seq 모델을 활용한 <strong>Parametric Memory</strong>와 <strong>Non-Parametric Memory</strong>를 구성했다.</li>
<li>RAG models의 parametric memory는 seq2seq transformer이고, non-parametric memory는 wikipedia를 활용한 dense vector index이다. 이때의 dense vector를 생성하는 pre-trained neural retriever를 포함한다.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./RAG_Architecture.png" class="img-fluid figure-img"></p>
<figcaption>RAG Architecture</figcaption>
</figure>
</div>
</section>
<section id="method" class="level2">
<h2 class="anchored" data-anchor-id="method">Method</h2>
<p>We explore RAG models, which use the input sequence x to retrieve text documents z and use them as additional context when generating the target sequence y.</p>
<ul>
<li>우리가 RAG model을 다룰 때, input sequence x에 대해 text document 집합인 z를 검색하고, 이러한 z들을 additional context로 사용하여 target sequence y를 생성하는데에 사용한다.</li>
</ul>
<p>In one approach, RAG-Sequence, the model uses the same document to predict each target token. The second approach, RAG-Token, can predict each target token based on a different document. In the following, we formally introduce both models and then describe the pη and pθ components, as well as the training and decoding procedure.</p>
<ul>
<li>generation 단계에서 z를 사용하는 방식에 따라 RAG-Sequence와 RAG-Token 방식으로 구분한다.</li>
<li>Rag-Sequence은 각 token(1개의 output prediction에 사용된)을 예측하기 위해 같은 문서를 사용하고, Rag-Token은 각 token을 예측하기 위해 다른 문서를 사용한다</li>
</ul>
<section id="models" class="level4">
<h4 class="anchored" data-anchor-id="models"><strong>Models</strong></h4>
<section id="retriever-dpr" class="level5">
<h5 class="anchored" data-anchor-id="retriever-dpr"><strong>Retriever: DPR </strong></h5>
<p><span class="math inline">\(p_{\eta}(z|x) \propto\ exp \left(d(z)\right)^T q(x)\)</span></p>
<p>The retrieval component pη(z|x) is based on DPR [26]. DPR follows a bi-encoder architecture: where d(z) is a dense representation of a document produced by a BERTBASE document encoder [8], and q(x) a query representation produced by a query encoder, also based on BERTBASE.</p>
<ul>
<li>RAG의 retriever는 DPR로부터 가져온 것이다.</li>
<li>DPR은 Bert로 구성된 Bi-Encoder 구조를 가지고 있는데, <span class="math inline">\(d(z)\)</span>는 document를 색인할 벡터 데이터베이스를 생성하는 용도의 encoder이고, <span class="math inline">\(q(x)\)</span>는 입력 쿼리를 encoding하는 용도이다.</li>
<li>Non-Parametric Memory라고 한다.</li>
</ul>
</section>
<section id="rag-sequence" class="level5">
<h5 class="anchored" data-anchor-id="rag-sequence"><strong>RAG-Sequence</strong></h5>
<p>The RAG-Sequence model uses the same retrieved document to generate the complete sequence. Technically, it treats the retrieved document as a single latent variable that is marginalized to get the seq2seq probability p(y|x) via a top-K approximation. Concretely, the top K documents are retrieved using the retriever, and the generator produces the output sequence probability for each document, which are then marginalized,</p>
<p><span class="math inline">\(P_{RAG-Sequence}(y|x) \approx \sum_{z \in top-k(p(\cdot|x))} p_{\eta}(z|x)p_{\theta}(y|x,z) = \sum_{z \in top-k(p(\cdot|x))} p_{\eta}(z|x) \prod_{i}^{N} p_{\theta}(y_{i}|x,z,y_{1:i-1})\)</span></p>
<ul>
<li>1개의 output prediction이 token <span class="math inline">\(\{y_1, ..., y_N\}\)</span>로 구성되었다고 가정한다.</li>
<li><span class="math inline">\(y_i\)</span>번째 token을 구할 때, <span class="math inline">\(y_1\)</span>부터 <span class="math inline">\(y_{i-1}\)</span>까지의 token과 latent document z1을 사용한다.
<ul>
<li><span class="math inline">\(p(y_1) \leftarrow p(x, z_1, y_0)\)</span> , 아직 <span class="math inline">\(y_0\)</span>는 존재하지 않음</li>
<li><span class="math inline">\(p(y_2) \leftarrow p(x, z_1, y_1)\)</span></li>
<li><span class="math inline">\(p(y_3) \leftarrow p(x, z_1, y_{(1, 2)})\)</span></li>
<li><span class="math inline">\(p(y_4) \leftarrow p(x, z_1, y_{(1, 2, 3)})\)</span></li>
<li>…</li>
<li><span class="math inline">\(p(y_N) \leftarrow p(x, z_1, y_{1:N-1})\)</span></li>
</ul></li>
<li>k개의 z를 retriever로부터 찾아왔다는 가정이므로 k개의 document에 대해 반복할 수 있다.</li>
<li>각 자리(<span class="math inline">\(1, .., N\)</span>)별로 존재하는 K개의 Token을 marginalize한다.</li>
</ul>
</section>
<section id="rag-token" class="level5">
<h5 class="anchored" data-anchor-id="rag-token"><strong>RAG-Token</strong></h5>
<p>In the RAG-Token model we can draw a different latent document for each target token and marginalize accordingly. This allows the generator to choose content from several documents when producing an answer. Concretely, the top K documents are retrieved using the retriever, and then the generator produces a distribution for the next output token for each document, before marginalizing, and repeating the process with the following output token, Formally, we define:</p>
<p><span class="math inline">\(P_{RAG-TOKEN}(y|x) \approx \prod_{i}^{N} \sum_{z \in top-k(p(\cdot|x))}p_{\eta}(z|x)p_{\theta}(y_{i}|x,z,y_{1:i-1})\)</span></p>
<ul>
<li>1개의 output prediction이 token <span class="math inline">\(\{y_1, ..., y_N\}\)</span>로 구성되었다고 가정한다.</li>
<li><span class="math inline">\(y_i\)</span>번째 token을 구할 때, <span class="math inline">\(y_1\)</span>부터 <span class="math inline">\(y_{i-1}\)</span>까지의 token을 준비한다.
<ul>
<li>이 토큰들과 latent <span class="math inline">\(z_1\)</span>를 가지고 <span class="math inline">\(y_i\)</span> token 확률을 구한다.</li>
<li>이 토큰들과 latent <span class="math inline">\(z_2\)</span>를 가지고 <span class="math inline">\(y_i\)</span> token 확률을 구한다.</li>
<li>…</li>
<li>이 토큰들과 latent <span class="math inline">\(z_k\)</span>를 가지고 <span class="math inline">\(y_i\)</span> token 확률을 구한다.</li>
</ul></li>
<li>구해진 k개의 token 후보들을 가지고 marginalize하여 <span class="math inline">\(y_i\)</span>번째 token을 구한다.</li>
</ul>
</section>
<section id="generator-bart" class="level5">
<h5 class="anchored" data-anchor-id="generator-bart"><strong>Generator: BART</strong></h5>
<p>The generator component pθ(yi |x, z, y1:i−1) could be modelled using any encoder-decoder. We use BART-large [32], a pre-trained seq2seq transformer [58] with 400M parameters. To combine the input x with the retrieved content z when generating from BART, we simply concatenate them. BART was pre-trained using a denoising objective and a variety of different noising functions.</p>
<ul>
<li>generator <span class="math inline">\(p_{\theta} (y_{i}|x, z, y_{1:i-1})\)</span> 는 BART-Large 400M 모델을 사용한 encoder-decoder 구조이다.</li>
<li>input query x와 retrieved document z를 심플하게 concatenate하였다.</li>
<li>Parametric Memory라고 부른다.</li>
</ul>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>